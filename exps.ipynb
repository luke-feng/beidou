{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# To Avoid Crashes with a lot of nodes\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import copy\n",
    "import numpy as np\n",
    "import lightning as pl\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassRecall, MulticlassPrecision, MulticlassF1Score, MulticlassConfusionMatrix\n",
    "from torchmetrics import MetricCollection\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import random\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from lightning.pytorch.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Manager, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# configure logging at the root level of Lightning\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
    "# configure logging on module level, redirect to file\n",
    "logger = logging.getLogger(\"lightning.pytorch.core\")\n",
    "logger.addHandler(logging.FileHandler(\"core.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(\"pytorch_lightning\")\n",
    "log.propagate = False\n",
    "log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.utils.data as data, torchvision as tv\n",
    "from collections import OrderedDict\n",
    "from skimage.util import random_noise\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jifegi. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = cwd+'\\\\'+'exps.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST(\n",
    "    f\"{sys.path[0]}/data\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "mnist_val = MNIST(\n",
    "    f\"{sys.path[0]}/data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_val = Subset(mnist_val, range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModelMLP(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule for MNIST.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_metrics(self, phase, y_pred, y, loss=None):\n",
    "        \"\"\"\n",
    "        Calculate and log metrics for the given phase.\n",
    "        Args:\n",
    "            phase (str): One of 'Train', 'Validation', or 'Test'\n",
    "            y_pred (torch.Tensor): Model predictions\n",
    "            y (torch.Tensor): Ground truth labels\n",
    "            loss (torch.Tensor, optional): Loss value\n",
    "        \"\"\"\n",
    "        if loss is not None:\n",
    "            self.log(f\"{phase}/Loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        y_pred_classes = torch.argmax(y_pred, dim=1)\n",
    "        if phase == \"Train\":\n",
    "            output = self.train_metrics(y_pred_classes, y, para=self.state_dict())\n",
    "            allmetrics = output\n",
    "            allmetrics['loss'] = loss\n",
    "            self.allmetrics.append(output)\n",
    "        elif phase == \"Validation\":\n",
    "            output = self.val_metrics(y_pred_classes, y, para=self.state_dict())\n",
    "        elif phase == \"Test\":\n",
    "            output = self.test_metrics(y_pred_classes, y, para=self.state_dict())\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # print(f\"y_pred shape: {y_pred.shape}, y_pred_classes shape: {y_pred_classes.shape}, y shape: {y.shape}\")  # Debug print\n",
    "        output = {f\"{phase}/{key.replace('Multiclass', '').split('/')[-1]}\": value for key, value in output.items()}\n",
    "        self.log_dict(output, prog_bar=True, logger=True)\n",
    "\n",
    "        if self.cm is not None:\n",
    "            self.cm.update(y_pred_classes, y)\n",
    "\n",
    "    def log_metrics_by_epoch(self, phase, print_cm=False, plot_cm=False):\n",
    "        \"\"\"\n",
    "        Log all metrics at the end of an epoch for the given phase.\n",
    "        Args:\n",
    "            phase (str): One of 'Train', 'Validation', or 'Test'\n",
    "            :param phase:\n",
    "            :param plot_cm:\n",
    "        \"\"\"\n",
    "        print(f\"Epoch end: {phase}, epoch number: {self.epoch_global_number[phase]}\")\n",
    "        if phase == \"Train\":\n",
    "            output = self.train_metrics.compute()\n",
    "            self.train_metrics.reset()\n",
    "        elif phase == \"Validation\":\n",
    "            output = self.val_metrics.compute()\n",
    "            self.val_metrics.reset()\n",
    "        elif phase == \"Test\":\n",
    "            output = self.test_metrics.compute()\n",
    "            self.test_metrics.reset()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        output = {f\"{phase}Epoch/{key.replace('Multiclass', '').split('/')[-1]}\": value for key, value in output.items()}\n",
    "        self.log_dict(output, prog_bar=True, logger=True)\n",
    "\n",
    "        if self.cm is not None:\n",
    "            cm = self.cm.compute().cpu()\n",
    "            # print(f\"{phase}Epoch/CM\\n\", cm) if print_cm else None\n",
    "            if plot_cm:\n",
    "                import seaborn as sns\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure(figsize=(10, 7))\n",
    "                ax = sns.heatmap(cm.numpy(), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "                ax.set_xlabel(\"Predicted labels\")\n",
    "                ax.set_ylabel(\"True labels\")\n",
    "                ax.set_title(\"Confusion Matrix\")\n",
    "                ax.set_xticks(range(10))\n",
    "                ax.set_yticks(range(10))\n",
    "                ax.xaxis.set_ticklabels([i for i in range(10)])\n",
    "                ax.yaxis.set_ticklabels([i for i in range(10)])\n",
    "                # self.logger.experiment.add_figure(f\"{phase}Epoch/CM\", ax.get_figure(), global_step=self.epoch_global_number[phase])\n",
    "                plt.close()\n",
    "\n",
    "        # Reset metrics\n",
    "\n",
    "        self.epoch_global_number[phase] += 1\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels=1,\n",
    "            out_channels=10,\n",
    "            learning_rate=1e-3,\n",
    "            metrics=None,\n",
    "            confusion_matrix=None,\n",
    "            seed=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.allmetrics = []\n",
    "        if metrics is None:\n",
    "            metrics = MetricCollection([\n",
    "                MulticlassAccuracy(num_classes=out_channels),\n",
    "                MulticlassPrecision(num_classes=out_channels),\n",
    "                MulticlassRecall(num_classes=out_channels),\n",
    "                MulticlassF1Score(num_classes=out_channels)\n",
    "            ])\n",
    "\n",
    "        \n",
    "        # Define metrics\n",
    "        self.train_metrics = metrics.clone(prefix=\"Train/\")\n",
    "        self.val_metrics = metrics.clone(prefix=\"Validation/\")\n",
    "        self.test_metrics = metrics.clone(prefix=\"Test/\")\n",
    "\n",
    "        if confusion_matrix is None:\n",
    "            self.cm = MulticlassConfusionMatrix(num_classes=out_channels)\n",
    "\n",
    "        # Set seed for reproducibility initialization\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "        self.example_input_array = torch.zeros(1, 1, 28, 28)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        self.l1 = torch.nn.Linear(28 * 28, 256)\n",
    "        self.l2 = torch.nn.Linear(256, 128)\n",
    "        self.l3 = torch.nn.Linear(128, out_channels)\n",
    "\n",
    "        self.epoch_global_number = {\"Train\": 0, \"Validation\": 0, \"Test\": 0}\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" \"\"\"\n",
    "        batch_size, channels, width, height = x.size()\n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.l1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l3(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def step(self, batch, phase):\n",
    "        images, labels = batch\n",
    "        images = images.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        y_pred = self.forward(images)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "\n",
    "        # Get metrics for each batch and log them\n",
    "        self.log(f\"{phase}/Loss\", loss, prog_bar=True)\n",
    "        self.process_metrics(phase, y_pred, labels, loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_id):\n",
    "        \"\"\"\n",
    "        Training step for the model.\n",
    "        Args:\n",
    "            batch:\n",
    "            batch_id:\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        return self.step(batch, \"Train\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log_metrics_by_epoch(\"Train\", print_cm=False, plot_cm=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step for the model.\n",
    "        Args:\n",
    "            batch:\n",
    "            batch_idx:\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        return self.step(batch, \"Validation\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log_metrics_by_epoch(\"Validation\", print_cm=False, plot_cm=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step for the model.\n",
    "        Args:\n",
    "            batch:\n",
    "            batch_idx:\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        return self.step(batch, \"Test\")\n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log_metrics_by_epoch(\"Test\", print_cm=False, plot_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelFlipping(dataset, indices, poisoned_percent=0, targeted=False, target_label=4, target_changed_label=7):\n",
    "    \"\"\"\n",
    "    select flipping_persent of labels, and change them to random values.\n",
    "    Args:\n",
    "        dataset: the dataset of training data, torch.util.data.dataset like.\n",
    "        indices: Indices of subsets, list like.\n",
    "        flipping_persent: The ratio of labels want to change, float like.\n",
    "    \"\"\"\n",
    "    new_dataset = copy.deepcopy(dataset)\n",
    "    targets = new_dataset.targets.detach().clone()\n",
    "    num_indices = len(indices)\n",
    "    # classes = new_dataset.classes\n",
    "    # class_to_idx = new_dataset.class_to_idx\n",
    "    # class_list = [class_to_idx[i] for i in classes]\n",
    "    class_list = set(targets.tolist())\n",
    "    if targeted == False:\n",
    "        num_flipped = int(poisoned_percent * num_indices)\n",
    "        if num_indices == 0:\n",
    "            return new_dataset\n",
    "        if num_flipped > num_indices:\n",
    "            return new_dataset\n",
    "        flipped_indice = random.sample(indices, num_flipped)\n",
    "\n",
    "        for i in flipped_indice:\n",
    "            t = targets[i]\n",
    "            flipped = torch.tensor(random.sample(class_list, 1)[0])\n",
    "            while t == flipped:\n",
    "                flipped = torch.tensor(random.sample(class_list, 1)[0])\n",
    "            targets[i] = flipped\n",
    "    else:\n",
    "        for i in indices:\n",
    "            if int(targets[i]) == int(target_label):\n",
    "                targets[i] = torch.tensor(target_changed_label)\n",
    "    new_dataset.targets = targets\n",
    "    return new_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelpoison(model: OrderedDict, poisoned_ratio, noise_type=\"gaussian\"):\n",
    "    \"\"\"\n",
    "    Function to add random noise of various types to the model parameter.\n",
    "    \"\"\"\n",
    "    poisoned_model = OrderedDict()\n",
    "\n",
    "    for layer in model:\n",
    "        bt = model[layer]\n",
    "        t = bt.detach().clone()\n",
    "        single_point = False\n",
    "        if len(t.shape) == 0:\n",
    "            t = t.view(-1)\n",
    "            single_point = True\n",
    "        # print(t)\n",
    "        if noise_type == \"salt\":\n",
    "            # Replaces random pixels with 1.\n",
    "            poisoned = torch.tensor(random_noise(t, mode=noise_type, amount=poisoned_ratio))\n",
    "        elif noise_type == \"gaussian\":\n",
    "            # Gaussian-distributed additive noise.\n",
    "            poisoned = torch.tensor(random_noise(t, mode=noise_type, mean=0, var=poisoned_ratio, clip=True))\n",
    "        elif noise_type == \"s&p\":\n",
    "            # Replaces random pixels with either 1 or low_val, where low_val is 0 for unsigned images or -1 for signed images.\n",
    "            poisoned = torch.tensor(random_noise(t, mode=noise_type, amount=poisoned_ratio))\n",
    "        else:\n",
    "            print(\"ERROR: @modelpoisoning: poison attack type not supported.\")\n",
    "            poisoned = t\n",
    "        if single_point:\n",
    "            poisoned = poisoned[0]\n",
    "        poisoned_model[layer] = poisoned\n",
    "\n",
    "    return poisoned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoison(dataset, indices, poisoned_percent, poisoned_ratio, targeted=False, target_label=3, noise_type=\"salt\", backdoor_validation=False):\n",
    "    \"\"\"\n",
    "    Function to add random noise of various types to the dataset.\n",
    "    \"\"\"\n",
    "    new_dataset = copy.deepcopy(dataset)\n",
    "    train_data = new_dataset.data\n",
    "    targets = new_dataset.targets\n",
    "    num_indices = len(indices)\n",
    "\n",
    "    if not targeted:\n",
    "        num_poisoned = int(poisoned_percent * num_indices)\n",
    "        if num_indices == 0:\n",
    "            return new_dataset\n",
    "        if num_poisoned > num_indices:\n",
    "            return new_dataset\n",
    "        poisoned_indice = random.sample(indices, num_poisoned)\n",
    "\n",
    "        for i in poisoned_indice:\n",
    "            t = train_data[i]\n",
    "            if noise_type == \"salt\":\n",
    "                # Replaces random pixels with 1.\n",
    "                noise_img = random_noise(t, mode=noise_type, amount=poisoned_ratio)\n",
    "                noise_img = np.array(255*noise_img, dtype = 'uint8')\n",
    "                poisoned = torch.tensor(noise_img)               \n",
    "\n",
    "            elif noise_type == \"gaussian\":\n",
    "                # Gaussian-distributed additive noise.\n",
    "                # poisoned = torch.tensor(random_noise(t, mode=noise_type, mean=0, var=poisoned_ratio, clip=True))\n",
    "                noise_img = random_noise(t, mode=noise_type, mean=0, var=poisoned_ratio, clip=True)\n",
    "                noise_img = np.array(255*noise_img, dtype = 'uint8')\n",
    "                poisoned = torch.tensor(noise_img)\n",
    "            elif noise_type == \"s&p\":\n",
    "                # Replaces random pixels with either 1 or low_val, where low_val is 0 for unsigned images or -1 for signed images.\n",
    "                # poisoned = torch.tensor(random_noise(t, mode=noise_type, amount=poisoned_ratio))\n",
    "                noise_img = random_noise(t, mode=noise_type, amount=poisoned_ratio)\n",
    "                noise_img = np.array(255*noise_img, dtype = 'uint8')\n",
    "                poisoned = torch.tensor(noise_img)\n",
    "            # elif noise_type == \"nlp_rawdata\":\n",
    "            #     # for NLP data, change the word vector to 0 with p=poisoned_ratio\n",
    "            #     poisoned = poison_to_nlp_rawdata(t, poisoned_ratio)\n",
    "            else:\n",
    "                print(\"ERROR: @datapoisoning: poison attack type not supported.\")\n",
    "                poisoned = t\n",
    "            train_data[i] = poisoned\n",
    "    else:\n",
    "        if backdoor_validation:\n",
    "            # mark all instances for testing\n",
    "            print(\"Datapoisoning: generating watermarked samples for testing (all classes)\")\n",
    "            for i in indices:\n",
    "                t = train_data[i]\n",
    "                poisoned = add_x_to_image(t)\n",
    "                train_data[i] = poisoned\n",
    "        else:\n",
    "            # only mark samples from specific target for training\n",
    "            print(\"Datapoisoning: generating watermarked samples for training, target: \" + str(target_label))\n",
    "            for i in indices:\n",
    "                if int(targets[i]) == int(target_label):\n",
    "                    t = train_data[i]\n",
    "                    poisoned = add_x_to_image(t)\n",
    "                    train_data[i] = poisoned\n",
    "    new_dataset.data = train_data\n",
    "    return new_dataset\n",
    "\n",
    "\n",
    "def add_x_to_image(img):\n",
    "    \"\"\"\n",
    "    Add a 10*10 pixels X at the top-left of a image\n",
    "    \"\"\"\n",
    "    size = 10\n",
    "    for i in range(0, size):\n",
    "        for j in range(0, size):\n",
    "            if i + j == size-1 or i == j:                \n",
    "                img[i][j] = 255\n",
    "    return torch.tensor(img).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeableSubset(Subset):\n",
    "    \"\"\"\n",
    "    Could change the elements in Subset Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 indices,\n",
    "                 label_flipping=False,\n",
    "                 data_poisoning=False,\n",
    "                 poisoned_percent=0,\n",
    "                 poisoned_ratio=0,\n",
    "                 targeted=False,\n",
    "                 target_label=0,\n",
    "                 target_changed_label=0,\n",
    "                 noise_type=\"salt\"):\n",
    "        super().__init__(dataset, indices)\n",
    "        new_dataset = copy.copy(dataset)\n",
    "        self.dataset = new_dataset\n",
    "        self.indices = indices\n",
    "        self.label_flipping = label_flipping\n",
    "        self.data_poisoning = data_poisoning\n",
    "        self.poisoned_percent = poisoned_percent\n",
    "        self.poisoned_ratio = poisoned_ratio\n",
    "        self.targeted = targeted\n",
    "        self.target_label = target_label\n",
    "        self.target_changed_label = target_changed_label\n",
    "        self.noise_type = noise_type\n",
    "\n",
    "        if self.label_flipping:\n",
    "            self.dataset = labelFlipping(self.dataset, self.indices, self.poisoned_percent, self.targeted, self.target_label, self.target_changed_label)\n",
    "        if self.data_poisoning:\n",
    "            self.dataset = datapoison(self.dataset, self.indices, self.poisoned_percent, self.poisoned_ratio, self.targeted, self.target_label, self.noise_type)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, list):\n",
    "            return self.dataset[[self.indices[i] for i in idx]]\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L0 norm, number of non zero items\n",
    "def l0_norm(x):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "    return torch.sum(x != 0).item()\n",
    "\n",
    "# L1 norm, abs value of all items\n",
    "def l1_norm(x):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "    return torch.sum(torch.abs(x)).item()\n",
    "\n",
    "# L2 norm, the square root of the sum of the squares of the items\n",
    "def l2_norm(x):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "    return torch.sqrt(torch.sum(x**2)).item()\n",
    "\n",
    "# L∞ norm, the maximum absolute value among the items\n",
    "def l_inf_norm(x):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "    return torch.max(torch.abs(x)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(mnist_train.targets)\n",
    "\n",
    "# Define function for Dirichlet sampling and balanced data distribution\n",
    "def dirichlet_sampling_balanced(targets, alpha, num_clients):\n",
    "    num_classes = len(np.unique(targets))\n",
    "    data_per_client = [[] for _ in range(num_clients)]\n",
    "    \n",
    "    for k in range(num_classes):\n",
    "        idx_k = np.where(targets == k)[0]\n",
    "        np.random.shuffle(idx_k)\n",
    "        proportions = np.random.dirichlet(np.repeat(alpha, num_clients))\n",
    "        proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "        splits = np.split(idx_k, proportions)\n",
    "        for i in range(num_clients):\n",
    "            data_per_client[i].extend(splits[i])\n",
    "    \n",
    "    # Ensure each client has the same number of samples\n",
    "    min_samples = min(len(data) for data in data_per_client)\n",
    "    balanced_data_per_client = [data[:min_samples] for data in data_per_client]\n",
    "    \n",
    "    return balanced_data_per_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_round = 5\n",
    "max_epoch = 3\n",
    "alpha_list = [100, 10, 1, 0.1, 0.01, 0.001]\n",
    "num_clients = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(client_indices, num_clients):\n",
    "    num_classes = len(np.unique(targets))\n",
    "    fig, axs = plt.subplots(1, num_clients, figsize=(8, 4))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        labels = mnist_train.targets[client_indices[i]]\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        axs[i].bar(unique, counts, tick_label=unique)\n",
    "        axs[i].set_title(f'Client {i+1}')\n",
    "        axs[i].set_xlabel('Class')\n",
    "        axs[i].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(models):\n",
    "    \"\"\"\n",
    "    Weighted average of the models.\n",
    "\n",
    "    Args:\n",
    "        models: Dictionary with the models (node: model, num_samples).\n",
    "    \"\"\"\n",
    "    if len(models) == 0:\n",
    "        return None\n",
    "\n",
    "    # Total Samples\n",
    "    total_samples = len(models)\n",
    "\n",
    "    # Create a Zero Model\n",
    "    accum = {layer: torch.zeros_like(param) for layer, param in models[0].items()}\n",
    "\n",
    "    # Add weighted models\n",
    "    for model in models:\n",
    "        for layer in accum:\n",
    "            accum[layer] += model[layer]\n",
    "\n",
    "    # Normalize Accum\n",
    "    for layer in accum:\n",
    "        accum[layer] /= total_samples\n",
    "        \n",
    "    # self.print_model_size(accum)\n",
    "\n",
    "    return accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class local_node():\n",
    "    def __init__(\n",
    "            self,\n",
    "            node_id: int,\n",
    "            experimentsName=None,\n",
    "            maxRound: int = 10,\n",
    "            maxEpoch: int = 3,\n",
    "            train_dataset=None,\n",
    "            test_dataset=None,\n",
    "            indices=[],\n",
    "            neiList=[],\n",
    "            experimentsName_path = None,\n",
    "            logger=None\n",
    "    ):\n",
    "        self.node_id = node_id\n",
    "        self.indices = indices\n",
    "        self.logger=logger\n",
    "        self.model = MNISTModelMLP()\n",
    "        self.neiList = neiList\n",
    "        self.maxRound = maxRound\n",
    "        self.maxEpoch = maxEpoch\n",
    "        self.experimentsName = experimentsName\n",
    "        self.nei_models = {}\n",
    "        self.dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        \n",
    "        tr_subset = ChangeableSubset(\n",
    "            self.dataset, indices)\n",
    "        self.data_train, self.data_val = random_split(\n",
    "                    tr_subset,\n",
    "                    [\n",
    "                        int(len(tr_subset) * 0.8),\n",
    "                        len(tr_subset) - int(len(tr_subset) * 0.8),\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "        \n",
    "        self.curren_round = 0\n",
    "        self.aggregated_model = MNISTModelMLP()\n",
    "\n",
    "        self.local_model_record = {}\n",
    "        self.local_model_record[0] = self.model\n",
    "\n",
    "        self.aggregated_model_record = {}\n",
    "        self.aggregated_model_record[0] = self.aggregated_model\n",
    "\n",
    "        self.nei_model_record = {}  \n",
    "        self.experimentsName_path = experimentsName_path      \n",
    "\n",
    "\n",
    "    def get_model(self):\n",
    "        model_info = self.model        \n",
    "        return model_info\n",
    "    \n",
    "    def next_round(self):\n",
    "        self.curren_round += 1\n",
    "\n",
    "    def get_current_round(self):\n",
    "        return self.curren_round\n",
    "\n",
    "    def set_model(self, round, model):\n",
    "        self.model_record[round] = model\n",
    "    \n",
    "    def set_current_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def set_current_aggregated_model(self, model):\n",
    "        self.aggregated_model = model\n",
    "    \n",
    "    def replace_local_aggregated_model(self):\n",
    "        self.model = self.aggregated_model\n",
    "\n",
    "    def get_neiList(self):\n",
    "        return self.neiList\n",
    "\n",
    "    def set_neiList(self, new_neiList):\n",
    "        self.neiList = new_neiList\n",
    "    \n",
    "    def add_nei_model(self, round, nei_id, nei_model):\n",
    "        if round in self.nei_model_record:\n",
    "            self.nei_model_record[round][nei_id]=nei_model\n",
    "        else:\n",
    "            self.nei_model_record[round] = {}\n",
    "            self.nei_model_record[round][nei_id]=nei_model\n",
    "       \n",
    "    def local_training(self):\n",
    "        # trainer = pl.Trainer(max_epochs=self.maxEpoch, accelerator='cuda', devices=-1) \n",
    "        trainer = pl.Trainer(logger=self.logger,\n",
    "                             max_epochs=self.maxEpoch, \n",
    "                             devices=1,\n",
    "                             accelerator=\"cuda\",\n",
    "                             enable_progress_bar=False,\n",
    "\n",
    "                            )\n",
    "        trainer.fit(self.model, train_dataloaders=DataLoader(self.data_train, batch_size=64,shuffle=True), val_dataloaders=DataLoader(self.data_val, batch_size=64,shuffle=False))\n",
    "\n",
    "        print(f\"Performance of Node {self.node_id} before aggregation at round {self.curren_round}\")\n",
    "        trainer.test(self.model, DataLoader(self.test_dataset, batch_size=64,shuffle=False))\n",
    "\n",
    "        trainer.save_checkpoint(f\"{self.experimentsName_path}/checkpoint_{self.experimentsName}_node_{self.node_id}_round_{self.curren_round}.ckpt\")\n",
    "\n",
    "\n",
    "    \n",
    "    def aggregation(self):\n",
    "        current_rount_nei_models = self.nei_model_record[self.curren_round]\n",
    "        nei_models_list = []\n",
    "        \n",
    "        for nei in current_rount_nei_models:\n",
    "            if nei in self.neiList:\n",
    "                nei_models_list.append(current_rount_nei_models[nei].state_dict())        \n",
    "        if self.node_id not in self.neiList:\n",
    "            nei_models_list.append(self.model.state_dict())\n",
    "            \n",
    "        print(f\"Node {self.node_id} aggregate model with {self.neiList}\")\n",
    "        aggregated_model_para = fed_avg(nei_models_list)     \n",
    "        self.aggregated_model.load_state_dict(aggregated_model_para)\n",
    "        self.replace_local_aggregated_model()\n",
    "\n",
    "        trainer = pl.Trainer(logger=self.logger,\n",
    "                             devices=1,\n",
    "                             accelerator=\"cuda\",) \n",
    "        print(f\"Performance of Node {self.node_id} after aggregation at round {self.curren_round}\")\n",
    "        trainer.test(self.model, DataLoader(self.test_dataset, batch_size=64,shuffle=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logger_config(project, group, dataset, dist_alpha, node_id, epoch, round):\n",
    "    config = {'project':project,\n",
    "              'group': group,\n",
    "              'name':f\"node_{node_id}\",\n",
    "              'config':{\n",
    "                  'dataset': dataset,\n",
    "                  'dist_alpha': dist_alpha,\n",
    "                  'round': round,\n",
    "                  'epoch': epoch\n",
    "              }}\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix_to_nei_list(adjacency_matrix):\n",
    "    nei_list = {}\n",
    "    for i, adj in enumerate(adjacency_matrix):\n",
    "        nei_list[i] = [i]\n",
    "        for nei, j in enumerate(adj):\n",
    "            if j == 1:\n",
    "                nei_list[i].append(nei)\n",
    "    return nei_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "G = nx.complete_graph(num_clients)\n",
    "adj_matrix = nx.adjacency_matrix(G).todense()\n",
    "nei_list = adjacency_matrix_to_nei_list(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "d:\\git\\beidou\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "d:\\git\\beidou\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjifegi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240527_190019-10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jifegi/local_test/runs/10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0' target=\"_blank\">node_0</a></strong> to <a href='https://wandb.ai/jifegi/local_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jifegi/local_test' target=\"_blank\">https://wandb.ai/jifegi/local_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jifegi/local_test/runs/10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0' target=\"_blank\">https://wandb.ai/jifegi/local_test/runs/10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 0 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "d:\\git\\beidou\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.894741952419281     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8860467076301575     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35079899430274963    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8960827589035034     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.894741952419281     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8970257043838501     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8959540128707886     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8964888453483582     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8970257043838501     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.894741952419281    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8860467076301575    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35079899430274963   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8960827589035034    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.894741952419281    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8970257043838501    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8959540128707886    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8964888453483582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8970257043838501    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\beidou\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "d:\\git\\beidou\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\beidou\\venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 1 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.87799072265625      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8686391115188599     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3793255090713501     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.878750741481781     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.87799072265625      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8815599679946899     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8805608749389648     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8823330402374268     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8815599679946899     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.87799072265625     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8686391115188599    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3793255090713501    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.878750741481781    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.87799072265625     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8815599679946899    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8805608749389648    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8823330402374268    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8815599679946899    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 2 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8900537490844727     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8821273446083069     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35455095767974854    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8932220339775085     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8900537490844727     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8917943239212036     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8920586705207825     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8945865631103516     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8917943239212036     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8900537490844727    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8821273446083069    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35455095767974854   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8932220339775085    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8900537490844727    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8917943239212036    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8920586705207825    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8945865631103516    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8917943239212036    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 3 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8828284740447998     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8746095299720764     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37141188979148865    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8869047164916992     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8828284740447998     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8849756121635437     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8854068517684937     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8909173011779785     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8849756121635437     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8828284740447998    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8746095299720764    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37141188979148865   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8869047164916992    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8828284740447998    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8849756121635437    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8854068517684937    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8909173011779785    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8849756121635437    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 4 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.874828040599823     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8676902651786804     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37007758021354675    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8846643567085266     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.874828040599823     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8797287344932556     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8811136484146118     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8881785273551941     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8797287344932556     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.874828040599823    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8676902651786804    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37007758021354675   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8846643567085266    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.874828040599823    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8797287344932556    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8811136484146118    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8881785273551941    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8797287344932556    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n",
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 5 before aggregation at round 1\n",
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8848905563354492     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8759658932685852     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36620715260505676    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8883396983146667     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8848905563354492     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8879159688949585     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8880476355552673     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8919119834899902     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8879159688949585     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8848905563354492    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8759658932685852    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36620715260505676   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8883396983146667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8848905563354492    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8879159688949585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8880476355552673    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8919119834899902    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8879159688949585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 6 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8918352723121643     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8822518587112427     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36182355880737305    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8907683491706848     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8918352723121643     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8936327695846558     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8934662938117981     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8946890830993652     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8936327695846558     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8918352723121643    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8822518587112427    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36182355880737305   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8907683491706848    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8918352723121643    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8936327695846558    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8934662938117981    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8946890830993652    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8936327695846558    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 7 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8766778111457825     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8684024214744568     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3799065053462982     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8791406750679016     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8766778111457825     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8803720474243164     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8799850940704346     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.882611870765686     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8803720474243164     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8766778111457825    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8684024214744568    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3799065053462982    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8791406750679016    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8766778111457825    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8803720474243164    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8799850940704346    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.882611870765686    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8803720474243164    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 8 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8859801292419434     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8758669495582581     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3810288608074188     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8888991475105286     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8859801292419434     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8894860744476318     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8876187801361084     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8898420929908752     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8894860744476318     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8859801292419434    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8758669495582581    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3810288608074188    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8888991475105286    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8859801292419434    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8894860744476318    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8876187801361084    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8898420929908752    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8894860744476318    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 9 before aggregation at round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8849754929542542     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8752703070640564     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35113638639450073    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8897188305854797     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8849754929542542     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8896682858467102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8882841467857361     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8911148309707642     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8896682858467102     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8849754929542542    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8752703070640564    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35113638639450073   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8897188305854797    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8849754929542542    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8896682858467102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8882841467857361    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8911148309707642    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8896682858467102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 aggregate model with [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Performance of Node 0 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 59.29it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 51.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1 aggregate model with [1, 0, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 1 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 64.28it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 54.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 2 aggregate model with [2, 0, 1, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 2 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 57.75it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 50.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 3 aggregate model with [3, 0, 1, 2, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 3 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 60.14it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 51.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 4 aggregate model with [4, 0, 1, 2, 3, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 4 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 51.33it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 44.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 5 aggregate model with [5, 0, 1, 2, 3, 4, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 5 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 62.60it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 53.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 6 aggregate model with [6, 0, 1, 2, 3, 4, 5, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 6 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 63.18it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 54.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 7 aggregate model with [7, 0, 1, 2, 3, 4, 5, 6, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 7 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 54.35it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 47.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 8 aggregate model with [8, 0, 1, 2, 3, 4, 5, 6, 7, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 8 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 56.06it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 49.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 9 aggregate model with [9, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 9 after aggregation at round 1\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 57.55it/s]Epoch end: Test, epoch number: 0\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 50.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01954919472336769    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2638888359069824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09999997913837433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01973862014710903    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010950000025331974    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01954919472336769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2638888359069824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09999997913837433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01973862014710903   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010950000025331974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\beidou\\venv\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:612: Checkpoint directory .\\local_test\\10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0\\checkpoints exists and is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 0 before aggregation at round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8595596551895142     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.848552942276001     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4455385208129883     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8616951107978821     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8595596551895142     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8611301183700562     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8600735664367676     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.86212557554245      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8611301183700562     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8595596551895142    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.848552942276001    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4455385208129883    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8616951107978821    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8595596551895142    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8611301183700562    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8600735664367676    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.86212557554245     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8611301183700562    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 1 before aggregation at round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8657131195068359     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8564701080322266     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.42121046781539917    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8709200024604797     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8657131195068359     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8682875633239746     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8692539930343628     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8724783658981323     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8682875633239746     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8657131195068359    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8564701080322266    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.42121046781539917   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8709200024604797    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8657131195068359    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8682875633239746    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8692539930343628    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8724783658981323    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8682875633239746    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n",
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 2 before aggregation at round 2\n",
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.8801309466362      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8697029948234558     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3918815553188324     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8804840445518494     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.8801309466362      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.882482647895813     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8811014294624329     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8812512159347534     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.882482647895813     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.8801309466362     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8697029948234558    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3918815553188324    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8804840445518494    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.8801309466362     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.882482647895813    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8811014294624329    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8812512159347534    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.882482647895813    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n",
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 3 before aggregation at round 2\n",
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8768753409385681     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8678365349769592     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40173953771591187    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8783442974090576     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8768753409385681     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8799382448196411     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8796802759170532     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8813920617103577     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8799382448196411     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8768753409385681    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8678365349769592    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40173953771591187   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8783442974090576    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8768753409385681    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8799382448196411    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8796802759170532    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8813920617103577    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8799382448196411    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n",
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 4 before aggregation at round 2\n",
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8773384690284729     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8663102388381958     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39977338910102844    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.878749430179596     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8773384690284729     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8810571432113647     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8793351650238037     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8792986869812012     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8810571432113647     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8773384690284729    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8663102388381958    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39977338910102844   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.878749430179596    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8773384690284729    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8810571432113647    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8793351650238037    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8792986869812012    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8810571432113647    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n",
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 5 before aggregation at round 2\n",
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8449869751930237     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8316877484321594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45438891649246216    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8537479639053345     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8449869751930237     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8480015993118286     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.845454752445221     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8602344989776611     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8480015993118286     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8449869751930237    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8316877484321594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45438891649246216   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8537479639053345    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8449869751930237    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8480015993118286    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.845454752445221    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8602344989776611    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8480015993118286    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 6 before aggregation at round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8764910697937012     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8650155067443848     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.42348846793174744    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8728647232055664     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8764910697937012     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.879285454750061     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8779247999191284     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8796870112419128     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.879285454750061     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8764910697937012    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8650155067443848    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.42348846793174744   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8728647232055664    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8764910697937012    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.879285454750061    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8779247999191284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8796870112419128    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.879285454750061    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 7 before aggregation at round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8711197376251221     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.858896017074585     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.41306570172309875    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8702453970909119     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8711197376251221     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8727263808250427     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8708598017692566     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8718446493148804     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8727263808250427     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8711197376251221    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.858896017074585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.41306570172309875   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8702453970909119    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8711197376251221    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8727263808250427    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8708598017692566    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8718446493148804    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8727263808250427    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n",
      "Performance of Node 8 before aggregation at round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8607325553894043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.847745954990387     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.42823004722595215    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8664141297340393     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8607325553894043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8620872497558594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.859958291053772     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8683316707611084     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8620872497558594     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8607325553894043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.847745954990387    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.42823004722595215   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8664141297340393    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8607325553894043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8620872497558594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.859958291053772    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8683316707611084    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8620872497558594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch end: Validation, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 1\n",
      "Epoch end: Train, epoch number: 0\n",
      "Epoch end: Validation, epoch number: 2\n",
      "Epoch end: Train, epoch number: 1\n",
      "Epoch end: Validation, epoch number: 3\n",
      "Epoch end: Train, epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 9 before aggregation at round 2\n",
      "Epoch end: Test, epoch number: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.862124502658844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8496243953704834     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43245500326156616    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8649979829788208     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.862124502658844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8657861948013306     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8629328012466431     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.867321252822876     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8657861948013306     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.862124502658844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8496243953704834    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43245500326156616   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8649979829788208    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.862124502658844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8657861948013306    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8629328012466431    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.867321252822876    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8657861948013306    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 aggregate model with [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Performance of Node 0 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 59.70it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 51.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.879852831363678     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8686854839324951     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37492746114730835    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8802041411399841     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.879852831363678     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8839101791381836     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8828378915786743     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.883851945400238     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8839101791381836     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.879852831363678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8686854839324951    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37492746114730835   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8802041411399841    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.879852831363678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8839101791381836    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8828378915786743    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.883851945400238    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8839101791381836    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1 aggregate model with [1, 0, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 1 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 59.46it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 51.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8787174820899963     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8670262098312378     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3731764554977417     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8787921667098999     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8787174820899963     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8827441930770874     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8816932439804077     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8829370737075806     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8827441930770874     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8787174820899963    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8670262098312378    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3731764554977417    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8787921667098999    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8787174820899963    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8827441930770874    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8816932439804077    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8829370737075806    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8827441930770874    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 2 aggregate model with [2, 0, 1, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 2 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 56.82it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:01<00:00, 22.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8789690136909485     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8673343658447266     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37458521127700806    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8797168135643005     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8789690136909485     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8822996020317078     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8810542821884155     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8825179934501648     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8822996020317078     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8789690136909485    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8673343658447266    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37458521127700806   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8797168135643005    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8789690136909485    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8822996020317078    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8810542821884155    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8825179934501648    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8822996020317078    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 3 aggregate model with [3, 0, 1, 2, 4, 5, 6, 7, 8, 9]\n",
      "Performance of Node 3 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 58.76it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 50.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8786160349845886     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8676171898841858     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3750391900539398     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8801395893096924     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8786160349845886     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8834092020988464     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8820896744728088     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8834376335144043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8834092020988464     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8786160349845886    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8676171898841858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3750391900539398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8801395893096924    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8786160349845886    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8834092020988464    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8820896744728088    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8834376335144043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8834092020988464    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 4 aggregate model with [4, 0, 1, 2, 3, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 4 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 58.35it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 50.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8798515796661377     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8686560988426208     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3767220377922058     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8812240362167358     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8798515796661377     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8841400742530823     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8826240301132202     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8839045763015747     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8841400742530823     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8798515796661377    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8686560988426208    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3767220377922058    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8812240362167358    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8798515796661377    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8841400742530823    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8826240301132202    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8839045763015747    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8841400742530823    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 5 aggregate model with [5, 0, 1, 2, 3, 4, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 5 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 51.42it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 44.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8805321455001831     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8695852160453796     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37834683060646057    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8829033374786377     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8805321455001831     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8845204710960388     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.883119523525238     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8846541047096252     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8845204710960388     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8805321455001831    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8695852160453796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37834683060646057   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8829033374786377    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8805321455001831    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8845204710960388    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.883119523525238    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8846541047096252    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8845204710960388    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 6 aggregate model with [6, 0, 1, 2, 3, 4, 5, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 6 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 58.43it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 50.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8815554976463318     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8702199459075928     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3786381483078003     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8821559548377991     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8815554976463318     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8851433992385864     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8838067650794983     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8852837681770325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8851433992385864     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8815554976463318    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8702199459075928    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3786381483078003    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8821559548377991    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8815554976463318    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8851433992385864    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8838067650794983    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8852837681770325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8851433992385864    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 7 aggregate model with [7, 0, 1, 2, 3, 4, 5, 6, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 7 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 58.66it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 50.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8811554312705994     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8699638843536377     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3789275586605072     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8818296194076538     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8811554312705994     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8846085071563721     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8832966089248657     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8846879601478577     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8846085071563721     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8811554312705994    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8699638843536377    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3789275586605072    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8818296194076538    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8811554312705994    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8846085071563721    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8832966089248657    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8846879601478577    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8846085071563721    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 8 aggregate model with [8, 0, 1, 2, 3, 4, 5, 6, 7, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 8 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 58.01it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 50.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8784967064857483     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8672717809677124     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37968939542770386    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8801773190498352     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8784967064857483     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8815690875053406     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.880192220211029     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8818618655204773     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8815690875053406     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8784967064857483    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8672717809677124    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37968939542770386   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8801773190498352    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8784967064857483    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8815690875053406    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.880192220211029    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8818618655204773    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8815690875053406    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 9 aggregate model with [9, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Node 9 after aggregation at round 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 59.12it/s]Epoch end: Test, epoch number: 2\n",
      "Testing DataLoader 0: 100%|██████████| 32/32 [00:00<00:00, 51.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8804000020027161     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Test/F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8691089749336243     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test/Loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.378052681684494     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Test/Precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8817535042762756     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        Test/Recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8804000020027161     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8836051225662231     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/F1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8822838068008423     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    TestEpoch/Precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8835824728012085     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     TestEpoch/Recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8836051225662231     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8804000020027161    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Test/F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8691089749336243    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test/Loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.378052681684494    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Test/Precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8817535042762756    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       Test/Recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8804000020027161    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8836051225662231    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/F1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8822838068008423    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   TestEpoch/Precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8835824728012085    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    TestEpoch/Recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8836051225662231    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test/Accuracy</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>Test/F1Score</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>Test/Loss</td><td>▁▁▁▁▁▁▁▁▁▁██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test/Precision</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>Test/Recall</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>TestEpoch/Accuracy</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>TestEpoch/F1Score</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>TestEpoch/Precision</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>TestEpoch/Recall</td><td>██████████▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>Train/Accuracy</td><td>▆▅▅▇▃▅▁▇▅▆▄▆▅▆▅▄▃█▁▆▃▅▂▆▃▄▅▅▃▇▃▄▃▄▄▅▆▅▂▅</td></tr><tr><td>Train/F1Score</td><td>▆▅▄▇▃▅▁▆▅▆▃▆▅▇▄▄▃█▂▆▃▅▂▆▂▄▄▅▃▇▂▄▃▄▄▄▆▄▂▅</td></tr><tr><td>Train/Loss</td><td>▃▄▆▂▅▂▅▃▅▃▄▅▄▂▅▄▅▁█▃▄▃▇▃▆▂▄▃▄▃▆▅▆▅▅▃▃▂▇▃</td></tr><tr><td>Train/Precision</td><td>▆▅▃▇▂▅▁▆▅▆▃▆▆▇▄▄▂█▃▇▃▆▂▆▂▄▄▅▃▇▂▅▃▄▃▄▆▃▃▆</td></tr><tr><td>Train/Recall</td><td>▆▅▅▇▃▅▁▇▅▆▄▆▅▆▅▄▃█▁▆▃▅▂▆▃▄▅▅▃▇▃▄▃▄▄▅▆▅▂▅</td></tr><tr><td>Train/loss</td><td>▃▄▆▂▅▂▅▃▅▃▄▅▄▂▅▄▅▁█▃▄▃▇▃▆▂▄▃▄▃▆▅▆▅▅▃▃▂▇▃</td></tr><tr><td>TrainEpoch/Accuracy</td><td>▃█▃█▂█▂▇▂█▁▇▂█▃█▂▇▂█▂▇▂█▁▇▁▇▃▇▁▆▁▇▂▇▂▇▁█</td></tr><tr><td>TrainEpoch/F1Score</td><td>▃█▃█▂█▂▇▂█▁▇▂█▃█▂█▃█▂▇▂█▁▇▂▇▃▇▁▆▁▇▂▇▂▇▁█</td></tr><tr><td>TrainEpoch/Precision</td><td>▃█▃█▃█▃▇▃█▃▇▃█▃█▂█▃█▂▇▃█▂▇▂▇▄▇▁▇▂▇▂▇▃█▁█</td></tr><tr><td>TrainEpoch/Recall</td><td>▃█▃█▂█▂▇▂█▁▇▂█▃█▂▇▂█▂▇▂█▁▇▁▇▃▇▁▆▁▇▂▇▂▇▁█</td></tr><tr><td>Validation/Accuracy</td><td>▃▆▅▇▄▆▄▆▅▇▃█▄▅▆▆▄▆▁▅▃▆▃▆▃▄▂▅▂▅▂▆▂▄▅▇▂▆▂▅</td></tr><tr><td>Validation/F1Score</td><td>▃▇▆▇▄▆▄▇▅█▃█▃▅▆▆▄▆▁▅▃▆▃▆▃▄▃▅▂▅▁▆▂▄▅▇▁▆▂▅</td></tr><tr><td>Validation/Loss</td><td>▅▂▄▂▅▃▄▁▄▁▅▁▄▁▄▃▄▁█▃▆▃▆▂▆▄▅▃▅▃▅▂▄▃▅▂▄▂▇▄</td></tr><tr><td>Validation/Precision</td><td>▄▇▆▇▅▇▅█▅█▄█▅▅▆▇▅▇▄▅▄▆▅▇▄▅▅▆▄▆▁▆▃▅▆▇▂▆▄▆</td></tr><tr><td>Validation/Recall</td><td>▃▆▅▇▄▆▄▆▅▇▃█▄▅▆▆▄▆▁▅▃▆▃▆▃▄▂▅▂▅▂▆▂▄▅▇▂▆▂▅</td></tr><tr><td>ValidationEpoch/Accuracy</td><td>▄▇▆▇▃▆▄▆▅█▃▇▄▆▅▆▄▆▁▅▃▆▃▇▃▄▂▄▂▅▂▅▃▄▅▇▂▆▃▅</td></tr><tr><td>ValidationEpoch/F1Score</td><td>▄▇▆▇▄▆▄▇▅█▃▇▄▆▆▆▅▇▂▅▃▆▄▇▄▄▃▅▃▆▁▆▃▅▅▇▂▆▃▆</td></tr><tr><td>ValidationEpoch/Precision</td><td>▄▇▆█▅▇▅█▆█▄▇▅▇▆▇▆█▅▆▄▆▅▇▅▆▅▆▄▆▁▇▄▅▆▇▆▇▄▆</td></tr><tr><td>ValidationEpoch/Recall</td><td>▄▇▆▇▃▆▄▆▅█▃▇▄▆▅▆▄▆▁▅▃▆▃▇▃▄▂▄▂▅▂▅▃▄▅▇▂▆▃▅</td></tr><tr><td>epoch</td><td>▁▆▁▆▃▆▃█▃▁▆▁▆▁▆▃▆▃█▁▃▆▃█▃▁▆▁▆▁▆▃▆▃█▃▁▆▁▁</td></tr><tr><td>trainer/global_step</td><td>▃▇▃█▄█▆█▆▃▆▃▇▃█▄█▆█▁▄█▆█▆▃▆▃▇▃█▄█▆█▆▃▆▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test/Accuracy</td><td>0.8804</td></tr><tr><td>Test/F1Score</td><td>0.86911</td></tr><tr><td>Test/Loss</td><td>0.37805</td></tr><tr><td>Test/Precision</td><td>0.88175</td></tr><tr><td>Test/Recall</td><td>0.8804</td></tr><tr><td>TestEpoch/Accuracy</td><td>0.88361</td></tr><tr><td>TestEpoch/F1Score</td><td>0.88228</td></tr><tr><td>TestEpoch/Precision</td><td>0.88358</td></tr><tr><td>TestEpoch/Recall</td><td>0.88361</td></tr><tr><td>Train/Accuracy</td><td>0.87306</td></tr><tr><td>Train/F1Score</td><td>0.87291</td></tr><tr><td>Train/Loss</td><td>0.3268</td></tr><tr><td>Train/Precision</td><td>0.9025</td></tr><tr><td>Train/Recall</td><td>0.87306</td></tr><tr><td>Train/loss</td><td>0.3268</td></tr><tr><td>TrainEpoch/Accuracy</td><td>0.89141</td></tr><tr><td>TrainEpoch/F1Score</td><td>0.89305</td></tr><tr><td>TrainEpoch/Precision</td><td>0.89531</td></tr><tr><td>TrainEpoch/Recall</td><td>0.89141</td></tr><tr><td>Validation/Accuracy</td><td>0.87266</td></tr><tr><td>Validation/F1Score</td><td>0.86315</td></tr><tr><td>Validation/Loss</td><td>0.40979</td></tr><tr><td>Validation/Precision</td><td>0.88024</td></tr><tr><td>Validation/Recall</td><td>0.87266</td></tr><tr><td>ValidationEpoch/Accuracy</td><td>0.8766</td></tr><tr><td>ValidationEpoch/F1Score</td><td>0.87731</td></tr><tr><td>ValidationEpoch/Precision</td><td>0.88649</td></tr><tr><td>ValidationEpoch/Recall</td><td>0.8766</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">node_0</strong> at: <a href='https://wandb.ai/jifegi/local_test/runs/10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0' target=\"_blank\">https://wandb.ai/jifegi/local_test/runs/10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0</a><br/> View project at: <a href='https://wandb.ai/jifegi/local_test' target=\"_blank\">https://wandb.ai/jifegi/local_test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240527_190019-10_clients_alpha_100_MNIST_fully27_05_2024_19_00_17_node_0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 100\n",
    "node_list = {}\n",
    "maxRound = 2\n",
    "maxEpoch = 3\n",
    "train_dataset = mnist_train\n",
    "test_dataset = mnist_val\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "\n",
    "experimentsName = f'{num_clients}_clients_alpha_{alpha}_MNIST_fully'+dt_string\n",
    "client_indices = dirichlet_sampling_balanced(targets, alpha, num_clients)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "logger_list = {}\n",
    "experimentsName_path = cwd+'/experiments/'+experimentsName\n",
    "os.mkdir(experimentsName_path)\n",
    "\n",
    "for client in range(num_clients):\n",
    "    indices = client_indices[client]\n",
    "    node_id = client  \n",
    "    \n",
    "    neiList = nei_list[client]\n",
    "    # logger_config = generate_logger_config('local_test', experimentsName, 'MNIST', alpha, node_id, maxEpoch, maxRound)\n",
    "    # logger = None\n",
    "    # wandb_logger = WandbLogger(project=\"local_test\", group=experimentsName, name = f\"node_{client}\", id = f\"{experimentsName}_node_{client}\", reinit=True, offline=True)   \n",
    "    csvlogger = CSVLogger(save_dir=experimentsName_path, name=f\"node_{client}\") \n",
    "    logger_list[node_id] = csvlogger\n",
    "\n",
    "    node = local_node(node_id, experimentsName, maxRound, maxEpoch, train_dataset, test_dataset, indices, neiList, experimentsName_path, logger_list[node_id])\n",
    "    node_list[node_id] = node\n",
    "    # logger_list[node_id][0].experiment.finish()\n",
    "\n",
    "for round in range(maxRound):\n",
    "    for node_id in node_list:\n",
    "        node = node_list[node_id]\n",
    "        node.next_round()\n",
    "        node.local_training()\n",
    "        for nei in node.neiList:\n",
    "            node_list[nei].add_nei_model(round+1, node_id, node.model)\n",
    "    \n",
    "    for node_id in node_list:\n",
    "        node = node_list[node_id]\n",
    "        node.aggregation()\n",
    "\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models = {}\n",
    "for alpha in alpha_list:\n",
    "    client_indices = dirichlet_sampling_balanced(targets, alpha, num_clients)\n",
    "    plot_class_distribution(client_indices, num_clients)\n",
    "    for client in range(num_clients):\n",
    "        indices = client_indices[client] \n",
    "        tr_subset = ChangeableSubset(\n",
    "            mnist_train, indices)\n",
    "        data_train, data_val = random_split(\n",
    "                    tr_subset,\n",
    "                    [\n",
    "                        int(len(tr_subset) * 0.8),\n",
    "                        len(tr_subset) - int(len(tr_subset) * 0.8),\n",
    "                    ],\n",
    "                )\n",
    "        model = MNISTModelMLP()\n",
    "        client_models[f'client_{client}_alpha_{alpha}'] = {\n",
    "            'client': client,\n",
    "            'indices': indices,\n",
    "            'data_train': data_train,\n",
    "            'data_val': data_val,\n",
    "            'model': model,\n",
    "            'l0_norm': [],\n",
    "            'l1_norm': [],\n",
    "            'l2_norm': [],\n",
    "            'linf_norm': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [client_models[i]['model'].state_dict() for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_params(model_state_dict):\n",
    "    models_layer_flatten = torch.cat([param.view(-1) for layer, param in model_state_dict.items()], 0)\n",
    "    return models_layer_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'client_0_alpha_100'\n",
    "test_model = client_models[model_name]['model']\n",
    "test_data = client_models[model_name]['data_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_changes(current, previous):\n",
    "    changes = np.mean([torch.norm(current[layer] - previous[layer]) for layer in current])\n",
    "    return changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_subset = ChangeableSubset(\n",
    "            mnist_train, indices, label_flipping=False, targeted=False, data_poisoning=True, poisoned_percent=1, poisoned_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tr_subset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoisoing_client_models = {}\n",
    "for poisoned_percent in [0.2,0.4,0.6,0.8,1.0]:\n",
    "    client_indices = dirichlet_sampling_balanced(targets, 100, num_clients)\n",
    "    indices = client_indices[0]\n",
    "    tr_subset = ChangeableSubset(\n",
    "            mnist_train, indices, label_flipping=False, targeted=False,data_poisoning=True, poisoned_percent=poisoned_percent, poisoned_ratio=0.5)\n",
    "    \n",
    "    data_train, data_val = random_split(\n",
    "                    tr_subset,\n",
    "                    [\n",
    "                        int(len(tr_subset) * 0.8),\n",
    "                        len(tr_subset) - int(len(tr_subset) * 0.8),\n",
    "                    ],\n",
    "                )\n",
    "    \n",
    "    model = MNISTModelMLP()\n",
    "    datapoisoing_client_models[f'datapoisoing_client_{client}_pp_{poisoned_percent}'] = {\n",
    "        'client': client,\n",
    "        'indices': indices,\n",
    "        'data_train': data_train,\n",
    "        'data_val': data_val,\n",
    "        'model': model,\n",
    "        'l0_norm': [],\n",
    "        'l1_norm': [],\n",
    "        'l2_norm': [],\n",
    "        'linf_norm': []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in datapoisoing_client_models.keys():\n",
    "    for round in range(max_round):    \n",
    "        test_model = datapoisoing_client_models[model_name]['model']\n",
    "        test_data = datapoisoing_client_models[model_name]['data_train']\n",
    "        if round == 0:\n",
    "            trainer = pl.Trainer(max_epochs=max_epoch, accelerator='cuda', devices=1)  \n",
    "            trainer.fit(test_model, \n",
    "                    train_dataloaders=data.DataLoader(test_data, batch_size=64,shuffle=True))\n",
    "            trainer.test(test_model, data.DataLoader(mnist_val, batch_size=64,shuffle=True))\n",
    "            trainer.save_checkpoint(f\"checkpoint_{model_name}_{round}.ckpt\")\n",
    "        else:\n",
    "            new_max_epochs = trainer.max_epochs\n",
    "            new_trainer = pl.Trainer(max_epochs=new_max_epochs, accelerator='cuda', devices=1)\n",
    "            temp_model = MNISTModelMLP()\n",
    "            test_model = temp_model.load_from_checkpoint(f\"checkpoint_{model_name}_{round-1}.ckpt\")\n",
    "            datapoisoing_client_models[model_name]['model']=test_model\n",
    "            new_trainer.fit(test_model, \n",
    "                    train_dataloaders=data.DataLoader(test_data, batch_size=64,shuffle=True))\n",
    "            new_trainer.test(test_model, data.DataLoader(mnist_val, batch_size=64,shuffle=True))\n",
    "            new_trainer.save_checkpoint(f\"checkpoint_{model_name}_{round}.ckpt\")\n",
    "            old_model_dict = copy.deepcopy(temp_model.load_from_checkpoint(f\"checkpoint_{model_name}_{round-1}.ckpt\").state_dict())\n",
    "            current_model_dict = test_model.state_dict()\n",
    "            old_flatten = flatten_params(old_model_dict)\n",
    "            current_flatten = flatten_params(current_model_dict)\n",
    "            l0 = l0_norm(current_flatten-old_flatten)\n",
    "            l1 = l1_norm(current_flatten-old_flatten)\n",
    "            l2 = l2_norm(current_flatten-old_flatten)\n",
    "            linf = l_inf_norm(current_flatten-old_flatten)\n",
    "            datapoisoing_client_models[model_name]['l0_norm'].append(l0)\n",
    "            datapoisoing_client_models[model_name]['l1_norm'].append(l1)\n",
    "            datapoisoing_client_models[model_name]['l2_norm'].append(l2)\n",
    "            datapoisoing_client_models[model_name]['linf_norm'].append(linf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFlipping_client_models = {}\n",
    "\n",
    "\n",
    "for poisoned_percent in [0.2,0.4,0.6,0.8,1.0]:\n",
    "    client_indices = dirichlet_sampling_balanced(targets, 100, num_clients)\n",
    "    indices = client_indices[0]\n",
    "    tr_subset = ChangeableSubset(\n",
    "            mnist_train, indices, label_flipping=True, targeted=False, poisoned_percent=poisoned_percent)\n",
    "    \n",
    "    data_train, data_val = random_split(\n",
    "                    tr_subset,\n",
    "                    [\n",
    "                        int(len(tr_subset) * 0.8),\n",
    "                        len(tr_subset) - int(len(tr_subset) * 0.8),\n",
    "                    ],\n",
    "                )\n",
    "    \n",
    "    model = MNISTModelMLP()\n",
    "    labelFlipping_client_models[f'labelFlipping_client_{client}_pp_{poisoned_percent}'] = {\n",
    "        'client': client,\n",
    "        'indices': indices,\n",
    "        'data_train': data_train,\n",
    "        'data_val': data_val,\n",
    "        'model': model,\n",
    "        'l0_norm': [],\n",
    "        'l1_norm': [],\n",
    "        'l2_norm': [],\n",
    "        'linf_norm': []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoisoing_client_models['datapoisoing_client_1_pp_0.4']['l2_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFlipping_client_models['labelFlipping_client_1_pp_0.2']['l2_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models['client_1_alpha_0.001']['l2_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models['client_1_alpha_100']['l2_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for round in range(max_round):\n",
    "    for model_name in labelFlipping_client_models.keys():\n",
    "        test_model = labelFlipping_client_models[model_name]['model']\n",
    "        test_data = labelFlipping_client_models[model_name]['data_train']\n",
    "        if round == 0:\n",
    "            trainer = pl.Trainer(max_epochs=max_epoch, accelerator='cuda', devices=1)  \n",
    "            trainer.fit(test_model, \n",
    "                    train_dataloaders=data.DataLoader(test_data, batch_size=64,shuffle=True))\n",
    "            trainer.test(test_model, data.DataLoader(mnist_val, batch_size=64,shuffle=True))\n",
    "            trainer.save_checkpoint(f\"checkpoint_{model_name}_{round}.ckpt\")\n",
    "        else:\n",
    "            new_max_epochs = trainer.max_epochs\n",
    "            new_trainer = pl.Trainer(max_epochs=new_max_epochs, accelerator='cuda', devices=1)\n",
    "            temp_model = MNISTModelMLP()\n",
    "            test_model = temp_model.load_from_checkpoint(f\"checkpoint_{model_name}_{round-1}.ckpt\")\n",
    "            labelFlipping_client_models[model_name]['model']=test_model\n",
    "            new_trainer.fit(test_model, \n",
    "                    train_dataloaders=data.DataLoader(test_data, batch_size=64,shuffle=True))\n",
    "            new_trainer.test(test_model, data.DataLoader(mnist_val, batch_size=64,shuffle=True))\n",
    "            new_trainer.save_checkpoint(f\"checkpoint_{model_name}_{round}.ckpt\")\n",
    "            old_model_dict = copy.deepcopy(temp_model.load_from_checkpoint(f\"checkpoint_{model_name}_{round-1}.ckpt\").state_dict())\n",
    "            current_model_dict = test_model.state_dict()\n",
    "            old_flatten = flatten_params(old_model_dict)\n",
    "            current_flatten = flatten_params(current_model_dict)\n",
    "            l0 = l0_norm(current_flatten-old_flatten)\n",
    "            l1 = l1_norm(current_flatten-old_flatten)\n",
    "            l2 = l2_norm(current_flatten-old_flatten)\n",
    "            linf = l_inf_norm(current_flatten-old_flatten)\n",
    "            labelFlipping_client_models[model_name]['l0_norm'].append(l0)\n",
    "            labelFlipping_client_models[model_name]['l1_norm'].append(l1)\n",
    "            labelFlipping_client_models[model_name]['l2_norm'].append(l2)\n",
    "            labelFlipping_client_models[model_name]['linf_norm'].append(linf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benign model with non-iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in client_models.keys():    \n",
    "    for round in range(max_round):\n",
    "        test_model = client_models[model_name]['model']\n",
    "        test_data = client_models[model_name]['data_train']\n",
    "        if round == 0:\n",
    "            trainer = pl.Trainer(max_epochs=max_epoch, accelerator='cuda', devices=1)  \n",
    "            trainer.fit(test_model, \n",
    "                    train_dataloaders=data.DataLoader(test_data, batch_size=64,shuffle=True))\n",
    "            trainer.test(test_model, data.DataLoader(mnist_val, batch_size=64,shuffle=True))\n",
    "            trainer.save_checkpoint(f\"checkpoint_{model_name}_{round}.ckpt\")\n",
    "        else:\n",
    "            new_max_epochs = trainer.max_epochs\n",
    "            new_trainer = pl.Trainer(max_epochs=new_max_epochs, accelerator='cuda', devices=1)\n",
    "            temp_model = MNISTModelMLP()\n",
    "            test_model = temp_model.load_from_checkpoint(f\"checkpoint_{model_name}_{round-1}.ckpt\")\n",
    "            client_models[model_name]['model']=test_model\n",
    "            new_trainer.fit(test_model, \n",
    "                    train_dataloaders=data.DataLoader(test_data, batch_size=64,shuffle=True))\n",
    "            new_trainer.test(test_model, data.DataLoader(mnist_val, batch_size=64,shuffle=True))\n",
    "            new_trainer.save_checkpoint(f\"checkpoint_{model_name}_{round}.ckpt\")\n",
    "            old_model_dict = copy.deepcopy(temp_model.load_from_checkpoint(f\"checkpoint_{model_name}_{round-1}.ckpt\").state_dict())\n",
    "            current_model_dict = test_model.state_dict()\n",
    "            old_flatten = flatten_params(old_model_dict)\n",
    "            current_flatten = flatten_params(current_model_dict)\n",
    "            l0 = l0_norm(current_flatten-old_flatten)\n",
    "            l1 = l1_norm(current_flatten-old_flatten)\n",
    "            l2 = l2_norm(current_flatten-old_flatten)\n",
    "            linf = l_inf_norm(current_flatten-old_flatten)\n",
    "            client_models[model_name]['l0_norm'].append(l0)\n",
    "            client_models[model_name]['l1_norm'].append(l1)\n",
    "            client_models[model_name]['l2_norm'].append(l2)\n",
    "            client_models[model_name]['linf_norm'].append(linf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoisoing_client_models['datapoisoing_client_1_pp_1.0']['l2_norm']\n",
    "labelFlipping_client_models['labelFlipping_client_1_pp_1.0']['l2_norm']\n",
    "client_models['client_0_alpha_100']['l2_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFlipping_client_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFlipping_client_models['labelFlipping_client_1_pp_1.0']['l2_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models['client_0_alpha_100']['l2_norm']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
